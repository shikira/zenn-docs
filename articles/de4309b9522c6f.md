---
title: "AWS IoT Immersion Day ワークショップでIoT Core学び直し ２日目"
emoji: "🦔"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: ["aws", "iot"]
published: true
---

# はじめに

https://zenn.dev/shikira/articles/20240318-aws-iot-immersionday-workshop-iot-core

前回はIoT Coreの基礎部分についてワークショップで理解を深めましたが、今回はGreengrassを学びたいと思います。
前回はRaspberry PiをEdge Deviceとして利用したので、今回も同じようにRaspberry Piを使います。

# IoT Greengrass

https://catalog.workshops.aws/aws-iot-immersionday-workshop/en-US/aws-greengrassv2

Greengrassでは、セットアップ手順やコンポーネントの追加方法を学び、lambdaや機械学習コンポーネントを実際に動かしてみて理解を深めることができます。

## Lab 35 - Setting up AWS IoT GreengrassV2

![](https://static.us-east-1.prod.workshops.aws/public/9b43574d-4397-4ebc-8565-d26868869093/static/lab35-flow-01-lab35-00-overall.png)


Lab35ではGreengrassV2を使うための準備として、IoT CoreでThing作ったり、Edge DeviceでGreengrassをインストールしたりします。

Lab 35はあまり悩むところがなかったで、やったことを淡々と書いていきます。

### Step1: IoT Thingを作成する
IoTポリシー作ってEdgeデバイス(Raspberry Pi)に許可するIoT Coreデータプレーンへのアクセスを定義します。
AWS IoT Core以外のサービスアクセスを許可するためにはAssume Roleを許可する必要があります。これが今回のポイントだと思われます。
前回同様、`iot:Connect`や`iot:Publish`など、IoT Coreを使ってMQTT通信するためのアクションを許可します。
ラボに従うのであれば、Resourceは制限しなくてもOK。
今回追加になっているのは`greengrass:*`と`iot:AssumeRoleWithCertificate`の二つです。
Greengrassを使うワークショップなのでGreengrassデータプレーンへのアクセスは許可し、さらにRaspberry PiからAWSサービスへのアクセスを許可するためにAssumeRoleも許可しているようです。
```
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": "iot:Connect",
      "Resource": "*"
    },
    {
      "Effect": "Allow",
      "Action": "iot:Publish",
      "Resource": "*"
    },
    {
      "Effect": "Allow",
      "Action": "iot:Receive",
      "Resource": "*"
    },
    {
      "Effect": "Allow",
      "Action": "iot:Subscribe",
      "Resource": "*"
    },
    {
      "Effect": "Allow",
      "Action": "greengrass:*",
      "Resource": "*"
    },
    {
      "Effect": "Allow",
      "Action": "iot:AssumeRoleWithCertificate",
      "Resource": "arn:aws:iot:[region]:[123456789012]:rolealias/RatchetWorkshopRoleAlias"
    }
  ]
}
```
IoT PolicyできたらとりあえずThingとGroup作って、証明書を発行しIoT Policyを付与しました。この辺は特に悩むところはなさそう。

### Step2: Greenglassアクセス制御オブジェクトを定義する
このステップではRaspberry PiがAWSサービスにアクセスできるようにするために、先ほどのIoT Policyで指定していたRoleAliasを作りました。

IAMでトークン交換ロールのポリシーを作成します。ここでRaspberry Piにアクセス許可するAWSサービスを定義しています。
主にCloudWatch LogsとS3へのアクセスを許可しているようです。
```
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "VisualEditor0",
      "Effect": "Allow",
      "Action": [
        "logs:CreateLogGroup",
        "logs:CreateLogStream",
        "logs:PutLogEvents",
        "logs:DescribeLogStreams",
        "s3:GetBucketLocation",
        "s3:GetObject"
      ],
      "Resource": "*"
    }
  ]
}

```

次にIAMロールを作成します。Raspberry Piの代わりにロールを引き受ける認証トークンプロバイダーにAssume Roleを許可し、許可する権限として先ほど作ったIAMポリシーを追加します。

さらに作成したIAMロールにAWS IoT Coreでロールエイリアスを設定します。
ここで設定するロールエイリアスはIoT Coreポリシーで設定したエイリアスとなります。

### Step3: Greengrass coreをインストールする
Step3はRaspberry Pi側の設定となります。
Step2で作成した証明書をRaspberry PiとGreengrass Coreが要求するPythonのAWS IoT Device SDKをインストールしました。
さらに、Greengrass Core本体をダウンロード・インストールします。

その後、Greengrass Coreのconfig.yamlを編集して、証明書パス、リージョン、ロールエイリアス、endpointなんかを設定していきますが、とてもセットアップが簡単で驚きました。
設定が終わったら、最後にGreengrass Coreサービスをインストールして自動起動するようにします。

### Step4: Greengrass CLI
最後のStep4ではGreengrass coreが無事にインストールできたことを確認するためにGreengrass CLIをインストールします。
実際にやってみて、こんなに簡単に機能追加できるんだと驚きました。

# Lab 36 - Your First Greengrass Component

![](https://static.us-east-1.prod.workshops.aws/public/9b43574d-4397-4ebc-8565-d26868869093/static/lab35-flow-02-lab36-00-overall.png)

Lab 36はLab35で構築したGreengrass環境で、lambdaを起動してIoT CoreのMQTTにPUB/SUBするというものでした。
Lambdaを簡単にEdge側で動かせるし、デプロイが簡単だし、感動しました。

ただ、Raspberry Pi上に作ったlambdaコンポーネントが正常にデプロイせずに数時間はまりました。
`/greengrass/v2/logs/Ratchet_Hello.log`という作成したlambdaコンポーネントのログを見たところ`device or resource busy`となっていました。

![](/images/de4309b9522c6f/ratchet_hello_busy.png)

いろいろ調べたら、Raspberry PiでLambda動かすにはcgroup v1にしないといけないみたいで、、、

https://docs.aws.amazon.com/ja_jp/greengrass/v2/developerguide/troubleshooting.html

ちゃんとサポートプラットフォームの要件にも書かれているようで、、、

https://hdocs.aws.amazon.com/ja_jp/greengrass/v2/developerguide/setting-up.html

# Lab 40 - Running Machine Learning at the Edge

Lab 40では、画像分析の機械学習コンポーネントを作って、Raspberry Pi上でインストールし実行するというものでした。

こちらも特に悩みなく勧められたのですが、最後の最後ではまってしまい、、、結局分析できませんでした。。。というオチです。

後半でnbconvertインストールするとかMXNetインストールするといった環境構築があるのですが、インストールするとRaspberry Pi 3が熱暴走してハングアップしてしまい、画像分析を実行できませんでした。

# おわりに

ワークショップに従ってGreengrassV2の学習、検証をしてみました。
機能理解が進み、より深掘りしていきたいなとモチベーションが上がりました。
ただ、もはやGreengrass関係ないのですが、機械学習やりたいならそれ相応のEdgeデバイス環境を構築しないといけないのだなと学びを得ました。
また、デバイス使って動かして検証してみるとデバイス周りで結構トラブル起きるので、改めて実際にやってみることは大事だなと感じました。